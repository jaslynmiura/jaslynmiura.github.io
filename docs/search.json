[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Growing up in Hawaiʻi, Jaslyn was surrounded by a community and unique ecosystems that shaped her love for the environment. Learning about Hawaiian culture that is deeply intertwined with the land while also witnessing the effects of climate change on her home, inspired Jaslyn to work in the environmental science field. Jaslyn intends to return to Hawaiʻi to work alongside her community to apply traditional ecological knowledge and data science to advance sustainable development and conservation.\n\nEducation\n\nUniversity of Washington | Seattle, WA\nB.S. Environmental Science and Terrestrial Resource Management with a minor in Quantitative Science | September 2021 - June 2025\nUniversity of California, Santa Barbara | Santa Barbara, CA\nMaster’s of Environmental Data Science | August 2025 - June 2026 (expected)\n\n\nWhat I’ve Done\n\nSummer Undergraduate Research Fellow - Pacific Island Ecosystem Research Center\n• Wrangled climate and spatial data by utilizing the tidyverse and sf packages in R to conduct a spatial analysis of the biomes in Hawaiʻi. • Created various maps and graphs to deliver a final presentation summarizing research findings to cohort peers and supervisors • Supported various fieldwork projects involving seed collection and bird banding.\nPlant Macrofossil Photographer - Strömberg Paleobotany Lab, University of Washington\n• Handled macrofossil specimens and operated museum camera equipment and software to produce high-quality photographs, to contribute to the study of understand plant ecology in the Pacific Northwest during the mid-Miocene climatic optimum. • Adhered to proper file organization and open-window museum workspace protocols.\nData Analysis Intern - Quantitative Ecology Lab, University of Washington\n• Managed and processed high-volume camera trap imagery sets by downloading, reviewing, and classifying species and human activity, to explore relationships between human activities and wildlife spatial and temporal patterns.\n\n\n\nProfessional Interests"
  },
  {
    "objectID": "posts/eds223-blog-post/index.html",
    "href": "posts/eds223-blog-post/index.html",
    "title": "Determining Exclusive Economic Zones for Marine Aquaculture Species",
    "section": "",
    "text": "How can sea surface temperature and depth rasters be used to determine what areas may be suitable to raise different marine aquaculture species?"
  },
  {
    "objectID": "posts/eds223-blog-post/index.html#data-cleaning",
    "href": "posts/eds223-blog-post/index.html#data-cleaning",
    "title": "Determining Exclusive Economic Zones for Marine Aquaculture Species",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nNOTE: When conducting a spatial analyses, we often want to ensure that our spatial objects have the same coordinate reference systems, resolutions, extents, etc. If statements and unit checks can be written within our code to check these conditions. These “gut checks” were written within the code folds.\nFor this analysis, we’ll be using Sea Surface Temperature rasters from 2008-2012. These rasters were obtained from the NOAA’s 5km Daily Global Satellite Sea Surface Temperature Anomaly v3.1. We’ll first stack the rasters into a single-multilayer raster. We will then calculate the mean sea surface temperature value for each cell across the five years. Therefore, each cell within avg_sst_rast represents the average sea surface temperature from 2008 to 2012 at that location. We’ll also convert the temperature units from Kelvin to Celsius by subtracting 273.15, using raster algebra\n\n# Load in Sea Surface Temperature rasters.\nsst_08 &lt;- rast(here::here('posts', 'eds223-blog-post', 'data', 'average_annual_sst_2008.tif'))\nsst_09 &lt;- rast(here::here('posts', 'eds223-blog-post', 'data', 'average_annual_sst_2009.tif'))\nsst_10 &lt;- rast(here::here('posts', 'eds223-blog-post', 'data', 'average_annual_sst_2010.tif'))\nsst_11 &lt;- rast(here::here('posts', 'eds223-blog-post', 'data', 'average_annual_sst_2011.tif'))\nsst_12 &lt;- rast(here::here('posts', 'eds223-blog-post', 'data', 'average_annual_sst_2012.tif'))\n\n\n# Stacking the 2008, 2009, 2010, 2011, and 2012 rasters.\nsst &lt;- c(sst_08, sst_09, sst_10, sst_11, sst_12)\n\n\n# Find the average SST of the stacked layers.\navg_sst_rast &lt;- mean(sst)\n\n\n# Convert the average SST from Kelvin to Celsius, by subtracting 273.15\navg_sst_rast &lt;- avg_sst_rast - 273.15\n\nDepth is another parameter we need for our analysis. This data was obtained from the General Bathymetric Chart of the Oceans (GEBCO). First, we’ll crop the raster to match the extent of the avg_sst_rast, to ensure that both rasters are within the same study area. We also want to make sure that the resolution of the rasters are the same. So we will resample the cropped depth raster to match the resolution of the avg_sst_rast, using the nearest neighbor method. This method assigns each output cell the value of the closest input cell, therefore the depth value in the depth_resample raster is simply the value from the nearest pixel in the original depth raster.\n\n# Loading the depth raster.\ndepth &lt;- rast(here::here('posts', 'eds223-blog-post', 'data', 'depth.tif'))\n\n\n\nCode\n# Check if coordinate reference systems match.\nif(crs(avg_sst_rast) == crs(depth)) {\n  print(\"CRS of 'avg_sst_rast' and 'depth' match.\")\n} else{\n  warning(\"Updating CRS of 'avg_sst_rast' and 'depth' to match.\")\n  # transform data to match\n  depth &lt;- project(depth, avg_sst_rast)\n}\n\n\nWarning: Updating CRS of 'avg_sst_rast' and 'depth' to match.\n\n\n\n# Cropping the depth raster to match the extent of the SST raster.\ndepth_crop &lt;- terra::crop(depth, avg_sst_rast)\n\n\n# Resampling the depth raster, using the nearest neighbor approach\ndepth_resample &lt;- resample(depth_crop, y = avg_sst_rast, method = \"near\")\n\n\n\nCode\n# Check that the depth_resample and avg_sst_rast match in resolution, extent, and crs.\nif(crs(avg_sst_rast) == crs(depth_resample)) {\n  print(\"CRS of 'avg_sst_rast' and 'depth_resample' match.\")\n} else{\n  warning(\"Updating CRS of 'avg_sst_rast' and 'depth_resample' to match.\")\n  # Transform data to match\n  avg_sst_rast &lt;- project(avg_sst_rast, depth_resample)\n}\n\n\n[1] \"CRS of 'avg_sst_rast' and 'depth_resample' match.\"\n\n\nCode\nif(resolution(avg_sst_rast) == resolution(depth_resample)) {\n  print(\"Resolutions of 'avg_sst_rast' and 'depth_resample' match.\")\n} else{\n  print(\"Resolutions of 'avg_sst_rast' and 'depth_resample' do not match.\")\n}\n\n\n[1] \"Resolutions of 'avg_sst_rast' and 'depth_resample' match.\"\n\n\nCode\nif(ext(avg_sst_rast) == ext(depth_resample)) {\n  print(\"Extents of 'avg_sst_rast' and 'depth_resample' match.\")\n} else{\n  print(\"Extents of 'avg_sst_rast' and 'depth_resample' do not match.\")\n}\n\n\n[1] \"Extents of 'avg_sst_rast' and 'depth_resample' match.\""
  },
  {
    "objectID": "posts/eds223-blog-post/index.html#spatial-analysis",
    "href": "posts/eds223-blog-post/index.html#spatial-analysis",
    "title": "Determining Exclusive Economic Zones for Marine Aquaculture Species",
    "section": "Spatial Analysis",
    "text": "Spatial Analysis\nWe’ll now reclassify our rasters, given certain parameters, using a reclassification matrix. Within the temperature matrix we are setting cells that have a sea surface temperature of 11-30 degrees Celsius as 1, and any other values as 0. Within the depth matrix we are setting cells that have a depth of -70-0 meters to 1, and any other values as 0. By reclassifying our rasters, we can then multiple the reclassified rasters to create a new raster, suitable_eez, which only selects the areas where 1x1=1.\n\n# Reclassify avg_sst_rast into locations that are suitable for oysters.\nrcl_temp &lt;- matrix(c(-Inf, 11, 0,\n                11, 30, 1,\n                30, Inf, 0),\n              ncol = 3, byrow = TRUE)\n\nreclassified_sst &lt;- classify(avg_sst_rast, rcl = rcl_temp)\n\nreclassified_sst[is.na(reclassified_sst)] &lt;- 0\n\n\n# Reclassify depth into locations that are suitable for oysters.\nrcl_depth &lt;- matrix(c(-Inf, -70, 0,\n                -70, 0, 1,\n                0, Inf, 0),\n              ncol = 3, byrow = TRUE)\n\nreclassified_depth &lt;- classify(depth_resample, rcl = rcl_depth)\n\nreclassified_depth[is.na(reclassified_depth)] &lt;- 0\n\n\n# Multiply depth and temperature rasters to find suitable areas for both conditions.\nsuitable_eez &lt;- (reclassified_depth)*(reclassified_sst)\n\n\n# Loading boundaries using west coast Exclusive Economic Zones.\nwest_coast &lt;- st_read(here::here('posts', 'eds223-blog-post', 'data', 'wc_regions_clean.shp'))\n\n\n\nCode\n# Check if the coordinate systems match.\nif(crs(suitable_eez) == crs(west_coast)) {\n  print(\"CRS of 'suitable_eez' and 'west_coast' match.\")\n} else{\n  warning(\"Updating CRS of 'suitable_eez' and 'west_coast' to match.\")\n  # transform data to match\n  west_coast &lt;- st_transform(west_coast, crs = st_crs(suitable_eez))\n}\n\n\nWarning: Updating CRS of 'suitable_eez' and 'west_coast' to match.\n\n\n\nDetermine the most suitable EEZ\n\n# Masking the suitable_eez raster to the west_coast regions.\nsuitable_eez_mask &lt;- mask(suitable_eez, west_coast)\n\n\n# Vectoirize west_coast boundary.\nwest_coast_vect &lt;- vect(west_coast)\n\n# Select the number suitable cells within west coast EEZs.\nregion_count &lt;- terra::extract(suitable_eez_mask, west_coast_vect, \n                               fun = \"sum\") %&gt;% \n  rename(suitable_cell_count = depth)\n\n# Use cellSize to change the units to kilometers.\ngrid_cell_km &lt;- cellSize(suitable_eez_mask, unit = \"km\")\n\n# Convert cells of mask raster into km^2.\nsuitable_area_rast &lt;- suitable_eez_mask * grid_cell_km\n\n# Calculate the area of suitable cells within west coast EEZ.\nregion_area &lt;- terra::extract(suitable_area_rast, west_coast_vect, \n                              fun = sum, na.rm = TRUE) %&gt;% \n  rename(suitable_area_oysters = depth)\n\n# Creating bins for suitable area.\nregion_area$suitable_area_bin_oysters &lt;- cut(\n  region_area$suitable_area_oysters,\n  breaks = c(0, 1000, 2000, 3000, 4000),\n  include.lowest = TRUE,\n  right = FALSE,\n  labels = c(\"0–1000\", \"1000–2000\", \"2000–3000\", \"3000–4000\"))\n\n# Joining the suitable region area to the west_coast boundary dataframe.\nwest_coast &lt;- west_coast %&gt;%\n  left_join(region_area, by = c(\"rgn_id\" = \"ID\")) \n\n\n\nCode\n# Creating a table of suitable area in each region.\nsuitable_df &lt;- west_coast %&gt;% \n  select(\"rgn\", \"suitable_area_oysters\") %&gt;% \n  st_drop_geometry() %&gt;% \n  kbl(escape = FALSE,\n        col.names = c(\"Region\", \"Suitable Area (km²)\"),\n        caption = \"Table 1: Suitable Area (km²) for Oysters\") %&gt;% \n  kable_styling(bootstrap_options = \"striped\")\nsuitable_df\n\n\n\nTable 1: Suitable Area (km²) for Oysters\n\n\nRegion\nSuitable Area (km²)\n\n\n\n\nOregon\n1028.9013\n\n\nNorthern California\n194.1284\n\n\nCentral California\n3656.8195\n\n\nSouthern California\n3062.2031\n\n\nWashington\n2435.9250\n\n\n\n\n\nThis table identifies the exact area that is determined to be suitable for Oysters. Looking at our map it may appear that the Central and Southern California regions both have the same amount of area suitable for Oysters, but this table tells us that the prime zone would be the Central California.\n\n# Create a map of the suitable area within each Exclusive Economic Zone.\ntm_graticules() +\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(west_coast) +\n  tm_polygons(fill = \"suitable_area_bin_oysters\",\n              fill.scale = tm_scale(values = \"brewer.pu_rd\"),\n              fill.legend = tm_legend(expression(\"Area km\"^{2}))) +\n  tm_title(text = \"Suitable Area of Oysters\")\n\n\n\n\n\n\n\n\nThis map compares the suitability of each region. Highlighting which regions have the highest area in km\\(^2\\) that can support a given species, in this case we are looking at oysters.\n\n\nIdentifying regions for other marine species\nTo identify other suitable regions for other marine species, a function was created, where only parameters required are the depth and temperature ranges, and the species name we are interested in. This function will create a map of new species we are interested in. The map identifies the regions along the west coast that contains the largest suitable areas for the marine species.\n\n\n\n\n\n\n\n\n\n\nTable 1: Suitable Area (km²) for Red Abalone\n\n\nRegion\nSuitable Area (km²)\n\n\n\n\nOregon\n504.4047\n\n\nNorthern California\n308.5819\n\n\nCentral California\n732.7807\n\n\nSouthern California\n713.2249\n\n\nWashington\n1687.8526\n\n\n\n\n\n\nReferences:\nLester, S. E., Gentry, R. R., & Froehlich, H. E. (2024). The role of marine aquaculture in contributing to the diversity and stability of U.S. seafood production. Marine Policy, 160, 105994. https://doi.org/10.1016/j.marpol.2023.105994\nWhat is the “EEZ”? - NOAA Ocean Exploration. (2023a, January 6). NOAA Ocean Exploration. https://oceanexplorer.noaa.gov/ocean-fact/useez/"
  },
  {
    "objectID": "posts/eds222-blog-post/analysis.html",
    "href": "posts/eds222-blog-post/analysis.html",
    "title": "Grazing Patterns of Herbivorous Fish in Moʻorea",
    "section": "",
    "text": "Due to changing climate conditions, macroalgae coverage can impact the transitional phases in coral colonization. Since coral reefs play such an important role in ecosystem services understanding coral reef dynamics is important. An aspect of this is understanding how macroalgae within the systems are being controlled. The herbivorous fishes Chlorurus sordidus, commonly known as parrot fish, and Ctenochaetus striatus, commonly known as striated surgeonfish are reef fish that feed on the algae directly impacting coral reefs.\nThis observation data in was collected from the coral reefs of Moʻorea, French Polynesia at research stations LTER 1 and Resilience 2. Focal fish species were identified by a SCUBA diver, an estimated fish length (cm), the depth at the start and end of the observation period, substrate types, and the number of bites taken within 5 minutes was recorded. The data was collected several days in July and August of 2010 between the times of 10:00 and 16:00, an identified period of time which corresponds to peak feeding rates for may herbivorous fishes (Adam, 2019).\nUsing this data we want to understand, how herbivore grazing bite counts are influenced by fish size, species, depth, and substrate.\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(janitor)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\n\n\nCode\n# Load in the data.\ndata1 &lt;- read_csv(here::here(\"posts\",\n                             \"eds222-blog-post\",\n                             \"data\",\n                             \"MCR_LTER_HerbBite_Focal_Herb_Bite_Rates_2010_20120521.csv\")) %&gt;% \n  clean_names() %&gt;%\n  dplyr::select(-c(time_period, depth_cat))\n\ndata2 &lt;- read_csv(here::here(\"posts\", \n                             \"eds222-blog-post\",\n                             \"data\", \n                             \"MCR_LTER_HerbBite_Addit_Bite_Rate_Data_2010_20120521.csv\")) %&gt;% \n  clean_names()\n\n# Stacking the datasets and dropping unnecessary columns.\nbite_data &lt;- rbind(data1, data2) %&gt;% \n  dplyr::select(-c(\"observer\", \"time_beg\", \"time_end\", \"stage\", \"notes\")) %&gt;% \n  drop_na()\n\n# Creating a mean_depth column.\nbite_data$mean_depth &lt;- (bite_data$depth_beg + bite_data$dept_end) / 2\n\n# Dropping the depth range columns.\nbite_data &lt;- bite_data %&gt;% \n  dplyr::select(-c(\"depth_beg\", \"dept_end\"))\n\n# Of the substrate type create a column of the dominant substrate.\nbite_data$dominant_substrate &lt;- apply(\n  bite_data[, c(\"bare\", \"rubble\", \"cca\", \"sand\", \"other\")],\n  1,\n  function(x) names(x)[which.max(x)])\n\n# Drop individual substrate columns make species and substrates factors.\nbite_data_clean &lt;- bite_data %&gt;% \n  dplyr::select(-c(\"bare\", \"rubble\", \"cca\", \"sand\", \"other\")) %&gt;% \n  mutate(species = factor(species),\n         dominant_substrate = factor(dominant_substrate))\n\n\nThe data source provides two datasets that hold data from observations from different dates and locations. After stacking the dataframes, columns that were not required for the analysis were dropped. Some cleaning of our variables was conducted. A mean_depth column was created, which is the average depth during each observation. This was created by taking the average depth between the recorded depth at the start and end of the observation. A dominant_substrate column was also created, which represents the substrate that was bitten the most of all the possible substrates. This was done by detecting which substrate had the highest number of bites, for each observed fish.\n\n\n\n\n\nCode\n# Plot of size vs. total bites, by species.\nggplot(data = bite_data_clean, aes(x = size_cm, y = total_bites, color = species)) +\n  geom_jitter() +\n  labs(x = \"Fish Length (cm)\",\n       y = \"Total number of bites\",\n       color = \"Species\") +\n  scale_color_manual(values = c(\"dodgerblue\", \"violet\")) +\n  theme_minimal()\n\n\n\n\n\nFigure 1: Total number of bites as a result of Fish Length (cm), by species, across 164 observed fish.\n\n\n\n\n\n\nCode\n# Plot of mean depth vs. total bites, by species\nggplot(data = bite_data_clean, aes(x = mean_depth, y = total_bites, color = species)) +\n  geom_jitter() +\n  labs(x = \"Mean depth (ft)\",\n       y = \"Total number of bites\",\n       color = \"Species\") +\n  scale_color_manual(values = c(\"dodgerblue\", \"violet\")) +\n  theme_minimal()\n\n\n\n\n\nFigure 2: Total number of bites as a result of Mean Depth (ft), by species, across 164 observed fish.\n\n\n\n\n\n\nCode\n# Total bite count distribution\nggplot(data = bite_data_clean, aes(x = total_bites)) +\n  geom_histogram(binwidth = 10,\n                 fill = \"black\") +\n  labs(x = \"Total number of bites\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\nFigure 3: Distribution of the Total number of bites.\n\n\n\n\nThe data is not normally distributed. The total number of bites is right skewed."
  },
  {
    "objectID": "posts/eds222-blog-post/analysis.html#data-collection-and-cleaning",
    "href": "posts/eds222-blog-post/analysis.html#data-collection-and-cleaning",
    "title": "Grazing Patterns of Herbivorous Fish in Moʻorea",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(janitor)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\n\n\nCode\n# Load in the data.\ndata1 &lt;- read_csv(here::here(\"posts\",\n                             \"eds222-blog-post\",\n                             \"data\",\n                             \"MCR_LTER_HerbBite_Focal_Herb_Bite_Rates_2010_20120521.csv\")) %&gt;% \n  clean_names() %&gt;%\n  dplyr::select(-c(time_period, depth_cat))\n\ndata2 &lt;- read_csv(here::here(\"posts\", \n                             \"eds222-blog-post\",\n                             \"data\", \n                             \"MCR_LTER_HerbBite_Addit_Bite_Rate_Data_2010_20120521.csv\")) %&gt;% \n  clean_names()\n\n# Stacking the datasets and dropping unnecessary columns.\nbite_data &lt;- rbind(data1, data2) %&gt;% \n  dplyr::select(-c(\"observer\", \"time_beg\", \"time_end\", \"stage\", \"notes\")) %&gt;% \n  drop_na()\n\n# Creating a mean_depth column.\nbite_data$mean_depth &lt;- (bite_data$depth_beg + bite_data$dept_end) / 2\n\n# Dropping the depth range columns.\nbite_data &lt;- bite_data %&gt;% \n  dplyr::select(-c(\"depth_beg\", \"dept_end\"))\n\n# Of the substrate type create a column of the dominant substrate.\nbite_data$dominant_substrate &lt;- apply(\n  bite_data[, c(\"bare\", \"rubble\", \"cca\", \"sand\", \"other\")],\n  1,\n  function(x) names(x)[which.max(x)])\n\n# Drop individual substrate columns make species and substrates factors.\nbite_data_clean &lt;- bite_data %&gt;% \n  dplyr::select(-c(\"bare\", \"rubble\", \"cca\", \"sand\", \"other\")) %&gt;% \n  mutate(species = factor(species),\n         dominant_substrate = factor(dominant_substrate))\n\n\nThe data source provides two datasets that hold data from observations from different dates and locations. After stacking the dataframes, columns that were not required for the analysis were dropped. Some cleaning of our variables was conducted. A mean_depth column was created, which is the average depth during each observation. This was created by taking the average depth between the recorded depth at the start and end of the observation. A dominant_substrate column was also created, which represents the substrate that was bitten the most of all the possible substrates. This was done by detecting which substrate had the highest number of bites, for each observed fish."
  },
  {
    "objectID": "posts/eds222-blog-post/analysis.html#data-exploration",
    "href": "posts/eds222-blog-post/analysis.html#data-exploration",
    "title": "Grazing Patterns of Herbivorous Fish in Moʻorea",
    "section": "",
    "text": "Code\n# Plot of size vs. total bites, by species.\nggplot(data = bite_data_clean, aes(x = size_cm, y = total_bites, color = species)) +\n  geom_jitter() +\n  labs(x = \"Fish Length (cm)\",\n       y = \"Total number of bites\",\n       color = \"Species\") +\n  scale_color_manual(values = c(\"dodgerblue\", \"violet\")) +\n  theme_minimal()\n\n\n\n\n\nFigure 1: Total number of bites as a result of Fish Length (cm), by species, across 164 observed fish.\n\n\n\n\n\n\nCode\n# Plot of mean depth vs. total bites, by species\nggplot(data = bite_data_clean, aes(x = mean_depth, y = total_bites, color = species)) +\n  geom_jitter() +\n  labs(x = \"Mean depth (ft)\",\n       y = \"Total number of bites\",\n       color = \"Species\") +\n  scale_color_manual(values = c(\"dodgerblue\", \"violet\")) +\n  theme_minimal()\n\n\n\n\n\nFigure 2: Total number of bites as a result of Mean Depth (ft), by species, across 164 observed fish.\n\n\n\n\n\n\nCode\n# Total bite count distribution\nggplot(data = bite_data_clean, aes(x = total_bites)) +\n  geom_histogram(binwidth = 10,\n                 fill = \"black\") +\n  labs(x = \"Total number of bites\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\nFigure 3: Distribution of the Total number of bites.\n\n\n\n\nThe data is not normally distributed. The total number of bites is right skewed."
  },
  {
    "objectID": "posts/eds222-blog-post/analysis.html#negative-binomial-regression-model-notation",
    "href": "posts/eds222-blog-post/analysis.html#negative-binomial-regression-model-notation",
    "title": "Grazing Patterns of Herbivorous Fish in Moʻorea",
    "section": "Negative Binomial Regression model notation:",
    "text": "Negative Binomial Regression model notation:\n\\[\n\\begin{aligned}\n\\text{BiteCount} &\\sim Negative Binomial(\\mu, \\theta)\n\\end{aligned}\n\\] \\[\n\\begin{aligned}\nlog(\\mu) &= \\beta_0 + \\beta_1 \\text{Size} + \\beta_2 \\text{Species} + \\beta_3 \\text{Depth} + \\beta_4 \\text{Substrate} \\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/eds222-blog-post/analysis.html#making-predictions-with-interactions-and-varying-mean-depth.",
    "href": "posts/eds222-blog-post/analysis.html#making-predictions-with-interactions-and-varying-mean-depth.",
    "title": "Grazing Patterns of Herbivorous Fish in Moʻorea",
    "section": "Making Predictions, with interactions and varying mean depth.",
    "text": "Making Predictions, with interactions and varying mean depth.\n\nfinal_model &lt;- glm.nb(total_bites ~ size_cm + species*mean_depth + dominant_substrate + offset(log(seconds_observed)), data = bite_data_clean)\n\n\n\nCode\nfinal_model_table &lt;- broom::tidy(final_model) %&gt;% \n  kbl(caption = \"Coeffieicent Estimates of the Full Additive Interactive Model\") %&gt;%\n  kable_paper(full_width=TRUE)\nfinal_model_table\n\n\n\nCoeffieicent Estimates of the Full Additive Interactive Model\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.1330416\n0.4784270\n-0.2780812\n0.7809500\n\n\nsize_cm\n-0.0647547\n0.0215775\n-3.0010257\n0.0026907\n\n\nspeciesCtenochaetus striatus\n-0.6869812\n0.3583561\n-1.9170349\n0.0552335\n\n\nmean_depth\n0.0061290\n0.0060036\n1.0208837\n0.3073096\n\n\ndominant_substraterubble\n0.0546794\n0.1300324\n0.4205060\n0.6741159\n\n\nspeciesCtenochaetus striatus:mean_depth\n0.0183200\n0.0080984\n2.2621793\n0.0236863\n\n\n\n\n\n\nCoefficient Interpretations:\n\\(\\beta_1\\) representing the size effect is again significant, where for every centimeter increase in fish length, the expected bite count decreases by 0.0648. \\(\\beta_2\\) representing the species effect. This coefficient specifically is the difference in expected bite counts between the species, when the depth is 0. Therefore, when depth is 0, we’d expect the bite count for parrot fish to be about 0.687 counts lower than striated surgeonfish. \\(\\beta_3\\) representing the depth effect on striated surgeonfish, is not significant. Meaning that depth does not affect the expected bite count of striated surgeonfish. \\(\\beta_4\\) representing the dominant substrate effect is again not significant. Therefore, when holding all other variables constant, substrate does not affect the expected bite count. \\(\\beta_5\\) representing the interaction between species and depth effect, is also the indicator of depth effect on parrot fish in relation to striated surgeonfish. Using the sum of estimate of \\(\\beta_3\\) and \\(\\beta_5\\) we can calculate the slope of depth’s effect on parrot fish expected bite counts. This means that for every meter increase in depth, expected bite counts for the parrot fish will increase by 0.02445.\nIn summary, this new additive interaction Negative Binomial Regression model indicates that again larger fish take less bites. Within this new model an important effect is that at deeper depths, the bite counts of parrot fish increase. However, the model does not indicate a similar significant pattern for striated surgeonfish. Therefore, the model reveals different behaviors and patterns within species related to herbivory grazing upon coral reefs."
  },
  {
    "objectID": "posts/eds220-blog-post/fires-blog.html",
    "href": "posts/eds220-blog-post/fires-blog.html",
    "title": "Mapping the 2025, Eaton and Palisades Fire Effects",
    "section": "",
    "text": "Credit: SASI SPACE - stock.adobe.com"
  },
  {
    "objectID": "posts/eds220-blog-post/fires-blog.html#task-1",
    "href": "posts/eds220-blog-post/fires-blog.html#task-1",
    "title": "Mapping the 2025, Eaton and Palisades Fire Effects",
    "section": "Task 1",
    "text": "Task 1\n\nLoad Data\n\n\nCode\n# Reading in the Eaton fire perimeter.\neaton_perimeter = gpd.read_file(os.path.join('data',\n                                             'Eaton_Perimeter_20250121',\n                                             'Eaton_Perimeter_20250121.shp'))\n\n# Reading in the Palisade fire perimeter.\npalisades_perimeter = gpd.read_file(os.path.join('data',\n                                                 'Palisades_Perimeter_20250121',\n                                                 'Palisades_Perimeter_20250121.shp'))\n\n# Reading in the landsat data.\nlandsat = xr.open_dataset(os.path.join('data',\n                                       'landsat8-2025-02-23-palisades-eaton.nc'))\n\n\n\n\nData Exploration\n\n\nCode\n# Using head() to view the first 5 rows of the eaton perimeter dataframe.\neaton_perimeter.head(5)\n\n\n\n\n\n\n\n\n\nOBJECTID\ntype\nShape__Are\nShape__Len\ngeometry\n\n\n\n\n0\n1\nHeat Perimeter\n2206.265625\n270.199719\nPOLYGON ((-13146936.686 4051222.067, -13146932...\n\n\n1\n2\nHeat Perimeter\n20710.207031\n839.204218\nPOLYGON ((-13150835.463 4052713.929, -13150831...\n\n\n2\n3\nHeat Perimeter\n3639.238281\n250.304502\nPOLYGON ((-13153094.697 4053057.596, -13153113...\n\n\n3\n4\nHeat Perimeter\n1464.550781\n148.106792\nPOLYGON ((-13145097.740 4053118.235, -13145100...\n\n\n4\n5\nHeat Perimeter\n4132.753906\n247.960744\nPOLYGON ((-13153131.126 4053196.882, -13153131...\n\n\n\n\n\n\n\n\n\nCode\n# Check the CRS of the eaton_perimeter.\nprint('CRS of the eaton_perimeter:', eaton_perimeter.crs)\n\n# Check if the eaton_perimeter data is projected or geographic.\nif eaton_perimeter.crs.is_projected:\n    print('The eaton_perimeter has a projected CRS')\nelse:\n    print('The eaton_perimeter has a geographic CRS')\n\n\nCRS of the eaton_perimeter: EPSG:3857\nThe eaton_perimeter has a projected CRS\n\n\n\n\nCode\n# Using head() to view the first 5 rows of the palisades_perimeter dataframe.\npalisades_perimeter.head(5)\n\n\n\n\n\n\n\n\n\nOBJECTID\ntype\nShape__Are\nShape__Len\ngeometry\n\n\n\n\n0\n1\nHeat Perimeter\n1182.082031\n267.101144\nPOLYGON ((-13193543.302 4032913.077, -13193543...\n\n\n1\n2\nHeat Perimeter\n2222.488281\n185.498783\nPOLYGON ((-13193524.155 4033067.953, -13193524...\n\n\n2\n3\nHeat Perimeter\n21.011719\n22.412814\nPOLYGON ((-13193598.085 4033158.222, -13193598...\n\n\n3\n4\nHeat Perimeter\n214.992188\n76.639180\nPOLYGON ((-13193654.249 4033146.033, -13193656...\n\n\n4\n5\nHeat Perimeter\n44203.453125\n1569.259764\nPOLYGON ((-13194209.580 4033236.320, -13194209...\n\n\n\n\n\n\n\n\n\nCode\n# Check the CRS of the palisades_perimeter.\nprint('CRS of the palisades_perimeter:', palisades_perimeter.crs)\n\n# Check if palisades_perimeter data is projected or geographic.\nif palisades_perimeter.crs.is_projected:\n    print('The palisades_perimeter has a projected CRS')\nelse:\n    print('The palisades_perimeter has a geographic CRS')\n\n\nCRS of the palisades_perimeter: EPSG:3857\nThe palisades_perimeter has a projected CRS\n\n\nPerimeter Data Description:\nThe Eaton and Palisades perimeter data sets are very similar. They both have projected CRS, where the CRS is ‘EPSG:3857’. From looking at the head of the datasets the we can see that both data sets have the same columns.\nLandsat Data\nThe landsat data is stored within an xarray dataset. Obtaining the data variables, dimensions, and coordinates of the the landsat xarray will help us fully understand the data and know how to handle the xarray when creating our maps.\n\n\nCode\n# Printing the type of the landsat data.\nprint('The landsat data is:', type(landsat))\n\n# Printing the data variables of the landsat data.\nprint('Data variables of the landsat data:\\n', landsat.data_vars)\n\n# Printing the dimensions of the landsat data.\nprint('Dimensions of the landsat data:', landsat.sizes)\n\n# Printing the coordinates of the landsat data.\nprint('Coordinates of the landsat data:', landsat.coords)\n\n\nThe landsat data is: &lt;class 'xarray.core.dataset.Dataset'&gt;\nData variables of the landsat data:\n Data variables:\n    red          (y, x) float32 16MB ...\n    green        (y, x) float32 16MB ...\n    blue         (y, x) float32 16MB ...\n    nir08        (y, x) float32 16MB ...\n    swir22       (y, x) float32 16MB ...\n    spatial_ref  int64 8B ...\nDimensions of the landsat data: Frozen({'y': 1418, 'x': 2742})\nCoordinates of the landsat data: Coordinates:\n  * y        (y) float64 11kB 3.799e+06 3.799e+06 ... 3.757e+06 3.757e+06\n  * x        (x) float64 22kB 3.344e+05 3.344e+05 ... 4.166e+05 4.166e+05\n    time     datetime64[ns] 8B ...\n\n\nLandsat Data Description:\nThe landsat data is an xarray dataset. The data variables of the xarray are red, green, blue, near-infrared, short-wave infrared, and spatial reference. Red, green, blue, near-infrared, and short-wave infrared are the bands that are a part of satellite data collection. the spatial reference variable holds information about the dataset, such as the CRS. The dimensions of the data set are {‘y’: 1418, ‘x’: 2742}, meaning there are 1418 rows and 2742 columns of pixels. The coordinates of the dataset are given as y and x as lists, where the starting coordinates provided are 3.799e+06 and 3.344e+05, respectively. A single time coordinate is provided too, which represents the time at which the landsat data was collected.\n\nLandsat xarray data wrangling\nDuring the data exploration, we noticed that the CRS of the xarrary is stored in the spatial reference variable. In the following section we’ll see that while the CRS may be documented within the xarray, it cannot be referenced through the rio.crs function. Therefore, we want to restore the CRS.\n\n\nCode\n# Printing the CRS of the landsat data.\nprint('The current CRS of the landsat data:', landsat.rio.crs)\n\n\nThe current CRS of the landsat data: None\n\n\n\n\nCode\n# Printing the CRS of the landsat data, which is stored in the spatial_ref variable.\nprint('CRS:', landsat.spatial_ref.crs_wkt)\n\n\nCRS: PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]\n\n\nHere we use .spatial_ref.crs_wkt to reference the CRS stored in the spatial reference variable. We can use rio.write_crs() to update the landsat’s CRS.\n\n\nCode\n# Setting the crs of the landsat data.\nlandsat = landsat.rio.write_crs(landsat.spatial_ref.crs_wkt)\n\n\n\n\nCode\n# Checking that the CRS of the landsat data was updated.\nprint('CRS:', landsat.rio.crs)\n\n\nCRS: EPSG:32611\n\n\n\n\nCreate a True Color Image Map\n\n\nCode\n# Replacing NA values with 0 and plotting the landsat data.\nlandsat[['red', 'green', 'blue']].fillna(0).to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\nCloud cover can create extreme outliers that cause the other values within the landsat data to be squished when plotting, which makes a plot appear “empty”. By setting imshow(robust=True) this ignores the cloud cover values. We also want replacing any nan values with 0 by using fillna(). By doing these two steps, this returns an optimal color scale for our true color image\n\n\nCreate a False Color Image\nCombining the fire perimeter boundaries and the false color image we can create a map of the fire scars.\n\n\nCode\n# Checking that the perimeter CRS and the landsat CRS are the same.\neaton_perimeter = eaton_perimeter.to_crs(landsat.rio.crs)\npalisades_perimeter = palisades_perimeter.to_crs(landsat.rio.crs)\nassert eaton_perimeter.crs == landsat.rio.crs\nassert palisades_perimeter.crs == landsat.rio.crs\n\n\n\n\nCode\n# Create false color image/map.\nfig, ax=plt.subplots(figsize=(12,10))\n\n# Remove the axis for a cleaner map\nax.axis('off')\n\nlandsat[['swir22', 'nir08', 'red']].fillna(0).to_array().plot.imshow(\n    ax=ax,\n    robust=True)\n\npalisades_perimeter.plot(ax=ax,\n               edgecolor='white',\n               facecolor='none',\n               linewidth= 1.5)\neaton_perimeter.plot(ax=ax,\n               edgecolor='white',\n               facecolor='none',\n               linewidth= 1.5)\n\nax.text(x=340000,\n         y=3775000,\n         s='Palisades',\n         color='white',\n         fontsize=18,\n         weight='bold')\n\nax.text(x=385000,\n        y=3790000,\n        s='Eaton',\n        color='white',\n        fontsize=18,\n        weight='bold')\n\nplt.title('False Color Image of Post Eaton and Palisades Fires (2025)')\n\nplt.show()"
  },
  {
    "objectID": "posts/eds220-blog-post/fires-blog.html#references",
    "href": "posts/eds220-blog-post/fires-blog.html#references",
    "title": "Mapping the 2025, Eaton and Palisades Fire Effects",
    "section": "References",
    "text": "References\nCenters for Disease Control and Prevention and Agency for Toxic Substances Disease Registry. [Year] Environmental Justice Index. Accessed [2025-11-21]. https://atsdr.cdc.gov/place-health/php/eji/eji-data-download.html\nCounty of Los Angeles, Geohub. (2025). Palisades and Eaton Dissolved Fire Perimeters (2025) [dataset]. County of Los Angeles. https://geohub.lacity.org/maps/ad51845ea5fb4eb483bc2a7c38b2370c/about\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 8-9 Operational Land Imager / Thermal Infrared Sensor Level-2, Collection 2 [dataset]. U.S. Geological Survey. https://doi.org/10.5066/P9OGBGM6"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jaslyn Miura",
    "section": "",
    "text": "I am a student in the data science field, inspired by my Hawaiʻi community, where the relationship between the land and people fuels my passion to protect the environment I grew up with, using the intersection of technology and tradition."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Determining Exclusive Economic Zones for Marine Aquaculture Species\n\n\n\nMEDS\n\nR\n\n\n\nSpatial analysis of suitable habitat areas along the west coast (USA) for marine aquaculture\n\n\n\nJaslyn Miura\n\n\nDec 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nMapping the 2025, Eaton and Palisades Fire Effects\n\n\n\nMEDS\n\nPython\n\n\n\nSpatial analysis in Python of fire effects.\n\n\n\nJaslyn Miura\n\n\nDec 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrazing Patterns of Herbivorous Fish in Moʻorea\n\n\n\nMEDS\n\nR\n\n\n\nEDS 222 Final Project: Statistical Analysis of bite rates on coral reefs in Moʻorea\n\n\n\nJaslyn Miura\n\n\nNov 27, 2025\n\n\n\n\n\n\n\n\n\n\n\nEDS 242 Blog Post\n\n\n\nMEDS\n\n\n\nEthics blog post!\n\n\n\nJaslyn Miura\n\n\nNov 12, 2025\n\n\n\n\n\n\nNo matching items"
  }
]